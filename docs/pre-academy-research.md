# üîç Pesquisa de Fundamentos e Modern Data Stack

> "A excel√™ncia n√£o √© um ato, mas um h√°bito de prepara√ß√£o cont√≠nua."

## üìñ Introdu√ß√£o e Justificativa

Este documento √© o resultado de uma imers√£o t√©cnica realizada de forma antecipada, utilizando como b√∫ssola as diretrizes apresentadas no **M√≥dulo Zero** do programa Lighthouse. 

Diferente de uma pesquisa gen√©rica, este levantamento foi estruturado a partir dos **Guias de Estudo oficiais** (Analytics Engineering, Data Engineering, Data Science e IA) e das sess√µes de **Data Talks** disponibilizadas pela Indicium. A decis√£o de consolidar estes conceitos antes do in√≠cio das aulas pr√°ticas fundamenta-se em tr√™s pilares estrat√©gicos:

### üéØ Por que iniciar esta pesquisa a partir do M√≥dulo Zero?

1.  **Alinhamento com a Metodologia Indicium:** O M√≥dulo Zero deixou claro que a transi√ß√£o para carreiras de dados exige uma mudan√ßa de mindset. Esta pesquisa visa sedimentar o "pensamento de Analytics Engineer" e a compreens√£o da Modern Data Stack (MDS) antes da execu√ß√£o t√©cnica.
2.  **Otimiza√ß√£o do Ciclo de Aprendizado:** Ao estudar previamente os temas sugeridos nos guias de Engenharia e Analytics, garanto que o tempo das aulas ao vivo ser√° utilizado para discuss√µes de alto n√≠vel e resolu√ß√£o de problemas complexos, maximizando o aproveitamento da mentoria.
3.  **Resposta √† Proatividade Exigida:** As trilhas de carreira e os talks sobre "como aprender tecnologia de forma eficiente" enfatizaram que a autonomia √© um diferencial no Lighthouse. Este documento √© a aplica√ß√£o pr√°tica dessa orienta√ß√£o: transformar as refer√™ncias te√≥ricas do M√≥dulo Zero em conhecimento estruturado.
4.  **Vis√£o Hol√≠stica (Full Stack Data):** Inspirado pela variedade de guias (Data Analytics a IA), busquei entender como essas √°reas se conectam dentro da arquitetura que a Indicium implementa, garantindo uma vis√£o sist√™mica do pipeline de dados.

---

## üõ†Ô∏è Eixos de Estudo (Diretrizes do M√≥dulo 0)

Com base nos referenciais t√©cnicos apresentados nos guias de estudo, esta pesquisa foca em:

* **Fundamentos Anal√≠ticos:** Diferencia√ß√£o entre ambientes transacionais (OLTP) e anal√≠ticos (OLAP).
* **Modelagem de Dados:** O pilar da Analytics Engineering conforme sugerido na "Aula Zero".
* **Arquitetura de Nuvem:** O papel dos Cloud Data Warehouses na escalabilidade de projetos.
* **Ferramental Estrat√©gico:** Introdu√ß√£o conceitual ao dbt e pr√°ticas de versionamento.

---

## üóÑÔ∏è Arquiteturas de Processamento: OLTP vs. OLAP

Para dominar a Engenharia de Dados, √© fundamental entender onde os dados nascem e para onde eles v√£o. Abaixo, detalho as duas arquiteturas principais com base nas defini√ß√µes t√©cnicas da IBM.

### 1. OLTP (Online Transactional Processing)
O foco aqui √© a **execu√ß√£o**. S√£o sistemas voltados para transa√ß√µes r√°pidas e frequentes.

* **Funcionamento:** Processa grandes volumes de transa√ß√µes simples (INSERT, UPDATE, DELETE) de forma simult√¢nea.
* **Caracter√≠sticas Principais:**
    * **Alta Disponibilidade:** Precisa estar no ar 24/7 (ex: sistema de um banco).
    * **Velocidade:** Respostas em milissegundos.
    * **Normaliza√ß√£o:** Dados s√£o organizados para evitar redund√¢ncia (geralmente em v√°rias tabelas relacionadas).
    * **Propriedades ACID:** Garante que as transa√ß√µes sejam At√¥micas, Consistentes, Isoladas e Dur√°veis.
* **Exemplos Pr√°ticos:**
    * Sistemas de PDV (caixa de supermercado).
    * Aplicativos de Internet Banking.
    * Sistemas de reserva de passagens a√©reas.

### 2. OLAP (Online Analytical Processing)
O foco aqui √© a **an√°lise**. S√£o sistemas voltados para consultas complexas e grandes volumes hist√≥ricos.

* **Funcionamento:** Consolida dados de diversas fontes OLTP para permitir descobertas, relat√≥rios e BI.
* **Caracter√≠sticas Principais:**
    * **Multidimensionalidade:** Permite analisar dados sob diferentes perspectivas (Tempo, Geografia, Produto).
    * **Dados Hist√≥ricos:** Armazena dados de meses ou anos para identificar tend√™ncias.
    * **Consultas Complexas:** Frequentemente envolve agrega√ß√µes (`SUM`, `AVG`, `COUNT`) em milh√µes de linhas.
    * **Desnormaliza√ß√£o:** Dados s√£o organizados para performance de leitura (ex: Star Schema).
* **Exemplos Pr√°ticos:**
    * Relat√≥rios de vendas anuais comparativos.
    * Previs√£o de demanda de estoque.
    * An√°lise de comportamento do consumidor (Churn).

---

### üìä Tabela Comparativa

| Caracter√≠stica | OLTP (Transacional) | OLAP (Anal√≠tico) |
| :--- | :--- | :--- |
| **Objetivo** | Executar o neg√≥cio (Operacional) | Analisar o neg√≥cio (Estrat√©gico) |
| **Fonte de Dados** | Opera√ß√µes em tempo real | Dados consolidados de OLTPs |
| **Queries** | Simples e r√°pidas | Complexas e demoradas |
| **Volume de Dados** | Gigabytes (dados atuais) | Terabytes/Petabytes (hist√≥rico) |
| **Usu√°rios** | Clientes, atendentes, sistemas | Analistas, Cientistas de Dados, Diretores |

---

### üí° Modern Data Stack
Na consultoria, o Engenheiro de Dados utiliza processos de **ELT** para extrair dados de sistemas **OLTP** (Postgres, MySQL, APIs) e carreg√°-los em um ambiente **OLAP** (Snowflake, BigQuery). Uma vez no ambiente OLAP, usamos o **dbt** para transformar esses dados brutos em modelos dimensionais que facilitam a vida do analista de BI.

---

### üßä O Conceito de Cubo OLAP
Diferente de uma tabela 2D (linhas e colunas), um **Cubo OLAP** √© uma estrutura multidimensional que permite visualizar dados atrav√©s de v√°rias "dimens√µes".

* **Funcionamento:** Imagine um cubo onde uma face √© o **Tempo** (anos/meses), outra √© o **Produto** e a outra √© a **Regi√£o**. O valor dentro do cubo (a **M√©trica**) seria o total de vendas.
* **Opera√ß√µes Principais:**
    * **Drill-down:** Aumentar o detalhe (ex: de Ano para Meses).
    * **Roll-up:** Consolidar os dados (ex: de Cidades para Estados).
    * **Slice & Dice:** Filtrar e "fatiar" o cubo para ver apenas uma parte espec√≠fica.

---

### üöÄ Varia√ß√µes de Arquitetura OLAP

Dependendo de como os dados s√£o armazenados e processados, o OLAP se divide em tr√™s modelos principais:

#### 1. MOLAP (Multidimensional OLAP)
Os dados s√£o armazenados em cubos propriet√°rios, altamente indexados e pr√©-calculados.
* **Uso:** Quando a performance de leitura √© cr√≠tica e as consultas s√£o repetitivas.
* **Pr√≥s:** Velocidade absurda em grandes volumes.
* **Contras:** Menos flex√≠vel; se voc√™ precisar de uma an√°lise que n√£o foi pr√©-calculada, o sistema sofre.

#### 2. ROLAP (Relational OLAP)
Os dados permanecem em bancos de dados relacionais tradicionais. A "l√≥gica do cubo" √© aplicada via SQL complexo em tempo de execu√ß√£o.
* **Uso:** Quando os dados mudam com frequ√™ncia ou a flexibilidade de consulta √© prioridade.
* **Pr√≥s:** Escal√°vel e utiliza a infraestrutura SQL j√° existente.
* **Contras:** Pode ser mais lento que o MOLAP para agrega√ß√µes massivas, pois processa tudo na hora.

#### 3. HOLAP (Hybrid OLAP)
O "melhor dos dois mundos". Mant√©m os dados detalhados no banco relacional (ROLAP) e as agrega√ß√µes pr√©-calculadas em cubos (MOLAP).
* **Uso:** Grandes corpora√ß√µes que precisam de detalhe m√°ximo e velocidade em relat√≥rios executivos.

---

### ‚òÅÔ∏è OLAP na Nuvem

Antigamente, manter sistemas OLAP exigia servidores gigantescos e caros. Hoje, a **Modern Data Stack** mudou o jogo com o **Cloud OLAP**.

* **Arquitetura Desacoplada:** Ferramentas como **Snowflake** e **BigQuery** separam o Armazenamento (Storage) do Processamento (Compute). Voc√™ paga apenas pelo que usa.
* **Elasticidade:** Se voc√™ precisa rodar uma query em 1 bilh√£o de linhas √†s 9h da manh√£, a nuvem escala 100 servidores para voc√™ e depois os desliga.
* **Diferencial t√©cnico:** No Cloud OLAP moderno, a distin√ß√£o entre ROLAP e MOLAP ficou t√™nue, pois o processamento em nuvem √© t√£o r√°pido que muitas vezes n√£o precisamos mais "pr√©-calcular" cubos r√≠gidos.

![Arquitetura OLAP e OLTP](images/OLAP-OLTP.png)

---

## üîÑ Integra√ß√£o de Dados: ETL vs. ELT

A integra√ß√£o de dados √© o processo de combinar dados de m√∫ltiplas fontes em um reposit√≥rio centralizado. A principal diferen√ßa entre ETL e ELT reside na ordem em que os dados s√£o transformados e onde esse processamento ocorre.

### 1. ETL (Extract, Transform, Load)
No modelo tradicional, os dados s√£o transformados em um servidor secund√°rio (staging area) antes de serem carregados no destino final.

* **Funcionamento:** Os dados s√£o extra√≠dos das fontes, passam por um processo de limpeza e formata√ß√£o fora do banco de dados de destino e, somente ap√≥s estarem "prontos", s√£o carregados no Data Warehouse.
* **Caracter√≠sticas Principais:**
    * **Processamento Externo:** Depende de motores de processamento dedicados para a transforma√ß√£o.
    * **Conformidade e Privacidade:** Ideal para remover dados sens√≠veis (LGPD/GDPR) antes mesmo de chegarem ao armazenamento.
    * **Estrutura R√≠gida:** Requer que o esquema de destino seja definido antes da carga (Schema-on-write).
* **Uso Ideal:** Ambientes com dados altamente estruturados e limita√ß√µes de processamento no banco de dados de destino (Sistemas On-premise).

### 2. ELT (Extract, Load, Transform)
O modelo moderno, impulsionado pela computa√ß√£o em nuvem, onde o dado bruto √© carregado diretamente e a transforma√ß√£o utiliza o poder do destino.

* **Funcionamento:** Os dados s√£o extra√≠dos e carregados imediatamente no Data Warehouse ou Data Lake. A transforma√ß√£o ocorre internamente, utilizando SQL ou linguagens de processamento distribu√≠do.
* **Caracter√≠sticas Principais:**
    * **Alta Escalabilidade:** Utiliza a elasticidade de Cloud Data Warehouses (como Snowflake e BigQuery).
    * **Flexibilidade:** Permite carregar dados brutos sem uma estrutura pr√©-definida (Schema-on-read), facilitando an√°lises futuras.
    * **Velocidade de Ingest√£o:** O processo de carga √© muito mais r√°pido, pois n√£o h√° o gargalo da transforma√ß√£o pr√©via.
* **Uso Ideal:** Big Data, Modern Data Stack e projetos que exigem agilidade na disponibiliza√ß√£o de novos dados.

---

### üìä Tabela Comparativa

| Caracter√≠stica | ETL (Tradicional) | ELT (Moderno) |
| :--- | :--- | :--- |
| **Sequ√™ncia** | Extrair ‚Üí Transformar ‚Üí Carregar | Extrair ‚Üí Carregar ‚Üí Transformar |
| **Local de Transforma√ß√£o** | Servidor de Processamento Independente | No pr√≥prio Data Warehouse/Lake |
| **Tempo de Carga** | Mais lento (devido √† transforma√ß√£o) | Mais r√°pido (carga direta) |
| **Volume de Dados** | Ideal para volumes pequenos/m√©dios | Projetado para Petabytes e Big Data |
| **Manuten√ß√£o** | Alta (mudan√ßas na fonte quebram o fluxo) | Baixa (o dado bruto est√° sempre dispon√≠vel) |

*Fonte das informa√ß√µes: Indicium Academy, AWS, Databricks.*

![Arquitetura ETL e ELT](images/ETL-ELT.png)

---

## üèóÔ∏è Reposit√≥rios de Dados: Warehouse vs. Lake vs. Lakehouse

A escolha da arquitetura de armazenamento define como uma empresa consegue processar, governar e extrair valor de seus ativos de dados.

### 1. Data Warehouse (DW)
Um reposit√≥rio centralizado projetado especificamente para an√°lise e relat√≥rios de neg√≥cios.

* **Funcionamento:** Armazena dados que j√° foram extra√≠dos, limpos e transformados (processo tradicional de ETL). Ele utiliza uma estrutura de "schema-on-write", o que significa que os dados devem ser organizados em um formato pr√©-definido antes de serem inseridos.
* **Caracter√≠sticas Principais:**
    * **Dados Estruturados:** Foca em dados altamente processados e organizados em tabelas.
    * **Performance Anal√≠tica:** Otimizado para consultas SQL complexas e r√°pidas.
    * **Governan√ßa Forte:** Oferece alto controle sobre quem acessa o qu√™ e garante a integridade dos dados.
* **Uso Ideal:** Business Intelligence (BI), relat√≥rios executivos e an√°lise de dados hist√≥ricos estruturados.

### 2. Data Lake
Um reposit√≥rio vasto que armazena dados em seu formato bruto e nativo.

* **Funcionamento:** Aceita qualquer tipo de dado (estruturado, semiestruturado ou n√£o estruturado) sem a necessidade de tratamento pr√©vio. Ele utiliza o conceito de "schema-on-read", onde a estrutura √© aplicada apenas quando o dado √© lido para an√°lise.
* **Caracter√≠sticas Principais:**
    * **Versatilidade:** Armazena desde logs de servidores e arquivos CSV at√© imagens e v√≠deos.
    * **Baixo Custo:** Geralmente utiliza armazenamento em nuvem de baixo custo para grandes volumes de dados.
    * **Escalabilidade:** Projetado para lidar com petabytes de informa√ß√µes de forma flex√≠vel.
* **Uso Ideal:** Ci√™ncia de Dados, Machine Learning, Big Data e armazenamento de longo prazo de dados brutos.

### 3. Data Lakehouse
Uma arquitetura h√≠brida que combina os melhores elementos do Data Warehouse e do Data Lake em uma √∫nica plataforma.

* **Funcionamento:** Implementa estruturas de dados e fun√ß√µes de gerenciamento de dados similares √†s de um DW (como transa√ß√µes ACID) diretamente sobre o armazenamento de baixo custo de um Data Lake.
* **Caracter√≠sticas Principais:**
    * **Unifica√ß√£o:** Elimina a necessidade de manter sistemas separados para BI e Machine Learning.
    * **Suporte a Transa√ß√µes ACID:** Garante que m√∫ltiplas partes possam ler e escrever dados simultaneamente sem erros.
    * **Esquemas Abertos:** Utiliza formatos de arquivos abertos (como Parquet ou Delta Lake) que podem ser lidos por diversas ferramentas.
* **Uso Ideal:** Empresas que buscam uma "fonte √∫nica da verdade" para engenharia de dados, ci√™ncia de dados e an√°lises em tempo real.

---

### üìä Tabela Comparativa

| Caracter√≠stica | Data Warehouse | Data Lake | Data Lakehouse |
| :--- | :--- | :--- | :--- |
| **Tipo de Dado** | Estruturado apenas | Estruturado e n√£o estruturado | Todos os tipos (unificado) |
| **Esquema** | Schema-on-write (R√≠gido) | Schema-on-read (Flex√≠vel) | Gerenciamento de esquema (H√≠brido) |
| **Custo** | Relativamente alto | Baixo | Baixo (pre√ßo de lake) |
| **P√∫blico Principal** | Analistas de BI e Neg√≥cios | Cientistas de Dados | Engenheiros, Analistas e Cientistas |

*Fontes: IBM, Microsoft Azure, Databricks.*

![Data Warehouse, lake e lakehouse](images/DW-DL-DLH.png)

---

## üèóÔ∏è Modelagem Dimensional: Metodologia Kimball e Estruturas de Dados

A modelagem dimensional √© o processo de organizar dados para facilitar a an√°lise e melhorar a performance de consultas em ambientes OLAP. O objetivo √© criar um "mapa" que os usu√°rios de neg√≥cio consigam entender intuitivamente.

### 1. Metodologia Kimball (The Kimball Group)
Desenvolvida por Ralph Kimball, esta metodologia adota uma abordagem "bottom-up" (de baixo para cima), focando nos processos de neg√≥cio para construir o Data Warehouse.

* **Os 4 Passos do Design Dimensional:**
    1. **Selecionar o Processo de Neg√≥cio:** (Ex: Vendas, Pedidos, Log√≠stica).
    2. **Declarar o Gr√£o:** Definir o n√≠vel de detalhe (Ex: Uma linha por item vendido por cupom fiscal).
    3. **Identificar as Dimens√µes:** Os substantivos da an√°lise (Quem, Onde, Quando, O qu√™).
    4. **Identificar as Fatos:** As m√©tricas quantitativas (Quanto, Valor, Quantidade).
* **Conceito Chave:** A modelagem deve ser centrada na facilidade de uso pelo analista e na performance de leitura.

### 2. Star Schema (Esquema Estrela)
√â a arquitetura mais simples e amplamente utilizada em Modern Data Stack.

* **Estrutura:** Uma tabela **Fato** central conectada diretamente a v√°rias tabelas **Dimens√£o**.
* **Caracter√≠sticas:**
    * **Desnormaliza√ß√£o:** As dimens√µes n√£o s√£o normalizadas, o que significa que h√° redund√¢ncia de dados para evitar JOINS complexos.
    * **Performance:** Excelente para consultas anal√≠ticas, pois exige menos jun√ß√µes entre tabelas.
    * **Uso Ideal:** Praticamente todos os Data Warehouses modernos (Snowflake, BigQuery).

#### 1. A Tabela Fato (O "O qu√™" e "Quanto")
A Tabela Fato √© o centro do Star Schema. Ela registra os eventos quantitativos de um processo de neg√≥cio.

* **Granularidade (Grain):** √â a defini√ß√£o do que uma √∫nica linha na tabela representa. Exemplo: "Uma linha por item vendido em cada transa√ß√£o". Definir o gr√£o √© o passo mais cr√≠tico da modelagem.
* **Chaves Estrangeiras (FKs):** A Fato n√£o cont√©m nomes ou descri√ß√µes; ela cont√©m IDs que se conectam √†s Dimens√µes.
* **Tipos de Medidas (Fatos):**
    * **Aditivas:** Podem ser somadas em todas as dimens√µes (Ex: Valor total da venda).
    * **Semi-aditivas:** Podem ser somadas em algumas dimens√µes, mas n√£o em todas (Ex: Saldo banc√°rio pode ser somado por regi√£o, mas n√£o por tempo/datas).
    * **N√£o aditivas:** Geralmente propor√ß√µes ou raz√µes que n√£o podem ser somadas (Ex: Margem de lucro unit√°ria).

#### 2. Tabelas Dimens√£o (O "Quem", "Onde" e "Quando")
As Dimens√µes fornecem o contexto descritivo para os fatos. Elas s√£o "chatas e largas", contendo muitas colunas de texto.

* **Atributos:** S√£o as colunas de texto usadas para filtrar e agrupar nos relat√≥rios (Ex: Nome do Produto, Categoria, Marca, Cor).
* **Surrogate Keys (Chaves Substitutas):** Em vez de usar o ID original do sistema (Natural Key), usa-se uma chave num√©rica simples criada pelo Data Warehouse. Isso √© essencial para lidar com SCDs e performance.
* **Desnormaliza√ß√£o:** Ao contr√°rio dos bancos OLTP, aqui as tabelas s√£o "achatadas". N√£o criamos uma tabela separada para 'Categoria'; colocamos o nome da categoria diretamente na tabela de 'Produto' para evitar Joins.

### 3. Snowflake Schema (Esquema Floco de Neve)
Uma varia√ß√£o do Star Schema onde as tabelas de dimens√£o s√£o normalizadas.

* **Estrutura:** As dimens√µes se ramificam em sub-dimens√µes (Ex: A dimens√£o 'Produto' se conecta a uma dimens√£o 'Categoria').
* **Caracter√≠sticas:**
    * **Normaliza√ß√£o:** Reduz a redund√¢ncia e economiza espa√ßo de armazenamento.
    * **Complexidade:** Exige mais JOINS, o que pode impactar a performance e tornar o SQL mais dif√≠cil de ler.
* **Uso Ideal:** Cen√°rios onde o custo de armazenamento √© extremamente alto ou quando a hierarquia dos dados √© muito complexa.

### 4. SCD (Slowly Changing Dimensions)
As "Dimens√µes que Mudam Lentamente" descrevem como o sistema lida com altera√ß√µes nos atributos das dimens√µes ao longo do tempo.

* **Tipos Mais Importantes:**

| Tipo | Nome | Funcionamento | Uso Ideal |
| :--- | :--- | :--- | :--- |
| **Tipo 0** | Fixo | O valor original √© mantido para sempre. Altera√ß√µes no sistema de origem s√£o ignoradas. | Dados imut√°veis como "Data de Nascimento" ou "ID Original". |
| **Tipo 1** | Sobrescrita | O valor antigo √© apagado e o novo √© inserido por cima. Perde-se o hist√≥rico. | Corre√ß√£o de erros ou quando o hist√≥rico n√£o tem valor (Ex: Corrigir erro de grafia). |
| **Tipo 2** | Hist√≥rico por Linha | Cria-se uma nova linha para o registro. Usa-se colunas `data_inicio`, `data_fim` e `versao_atual` (booleano). | **Padr√£o Ouro.** Essencial quando o hist√≥rico importa (Ex: Onde o cliente morava quando fez a compra X?). |
| **Tipo 3** | Hist√≥rico por Coluna | Cria-se uma nova coluna chamada `valor_anterior`. Mant√©m apenas a vers√£o atual e a imediatamente anterior. | Quando voc√™ s√≥ precisa comparar o "agora" com o "antes" de forma r√°pida. |
| **Tipo 4** | Tabela de Hist√≥rico | A tabela principal mant√©m apenas o dado atual (Tipo 1), mas todas as mudan√ßas s√£o gravadas em uma tabela de "log" separada. | Quando a tabela de dimens√£o √© gigantesca e muda com muita frequ√™ncia. |
| **Tipo 6** | H√≠brido (1+2+3) | Combina t√©cnicas: usa o Tipo 2 para rastrear hist√≥rico, mas tamb√©m colunas do Tipo 3 para acesso r√°pido. (2+3+1 = 6). | Relat√≥rios de alt√≠ssima complexidade que exigem vis√£o atual e hist√≥rica na mesma linha. |

---

### üìä Comparativo: Star vs. Snowflake

| Caracter√≠stica | Star Schema | Snowflake Schema |
| :--- | :--- | :--- |
| **Normaliza√ß√£o** | Desnormalizado | Normalizado |
| **Complexidade de Query** | Baixa (Menos Joins) | Alta (Mais Joins) |
| **Integridade de Dados** | Menor (Risco de redund√¢ncia) | Maior (Estrutura r√≠gida) |
| **Performance de Leitura** | Superior | Inferior |

*Fontes: Microsoft Learn, IBM Architecture, dbt Labs Documentation, The Data Warehouse Toolkit (Kimball).*

---
